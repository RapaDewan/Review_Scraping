{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:38:45.286430Z","iopub.execute_input":"2024-11-19T17:38:45.286850Z","iopub.status.idle":"2024-11-19T17:38:45.292461Z","shell.execute_reply.started":"2024-11-19T17:38:45.286802Z","shell.execute_reply":"2024-11-19T17:38:45.291406Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:38:52.740556Z","iopub.execute_input":"2024-11-19T17:38:52.741423Z","iopub.status.idle":"2024-11-19T17:38:53.802056Z","shell.execute_reply.started":"2024-11-19T17:38:52.741374Z","shell.execute_reply":"2024-11-19T17:38:53.801096Z"}},"outputs":[{"name":"stdout","text":"Tue Nov 19 17:38:53 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\n\nprint(\"Number of GPU: \", torch.cuda.device_count())\nprint(\"GPU Name: \", torch.cuda.get_device_name())\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:39:02.477099Z","iopub.execute_input":"2024-11-19T17:39:02.477989Z","iopub.status.idle":"2024-11-19T17:39:05.690740Z","shell.execute_reply.started":"2024-11-19T17:39:02.477933Z","shell.execute_reply":"2024-11-19T17:39:05.689797Z"}},"outputs":[{"name":"stdout","text":"Number of GPU:  1\nGPU Name:  Tesla P100-PCIE-16GB\nUsing device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Data Preprocessing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the scraped data from the provided URL\nurl = \"https://raw.githubusercontent.com/amanullahshah32/Review-Scraping/refs/heads/main/Dataset/cleaned_dataset.csv\"\ndf = pd.read_csv(url)\n\n# Drop rows where 'review_description' or 'rating' are missing\ndf.dropna(subset=['review_description', 'rating'], inplace=True)\n\n# Sample 1000 rows randomly\ndf = df.sample(n=1000, random_state=42)\n\n# Shuffle the dataset\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Create a sentiment column based on rating\ndf['sentiment'] = df['rating'].apply(lambda x: 0 if x <= 2 else (1 if x == 3 else 2))\n\n# Split into training and validation sets\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(df['review_description'], df['sentiment'], test_size=0.2, random_state=42)\n\n# Convert labels to list\ntrain_labels = train_labels.tolist()\nval_labels = val_labels.tolist()\n\n# Optional: Display the first few rows of the dataset\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:39:09.090289Z","iopub.execute_input":"2024-11-19T17:39:09.091250Z","iopub.status.idle":"2024-11-19T17:39:10.616686Z","shell.execute_reply.started":"2024-11-19T17:39:09.091214Z","shell.execute_reply":"2024-11-19T17:39:10.615561Z"}},"outputs":[{"name":"stdout","text":"        source                             review_id      user_name  \\\n0  Google Play  fcdb40a1-5476-4e43-9734-405793f4cf15  A Google user   \n1  Google Play  fc9f6420-2337-458d-9d6c-30dd6aa03202  A Google user   \n2  Google Play  c9d01e10-d443-482f-a4a2-cb40f6337fab  A Google user   \n3  Google Play  b7ad0a99-12e3-464f-b66e-1e837adb6620  A Google user   \n4  Google Play  ec02d7d8-3c1a-417c-9b1e-c00e69097e38  A Google user   \n\n   review_title                                 review_description  rating  \\\n0           NaN                                It is like a friend       5   \n1           NaN                       It is very useful to me.....       4   \n2           NaN  It's really good at telling me when I'm about ...       4   \n3           NaN  Remeind me better and make me free of stress ....       5   \n4           NaN  Easy way to track dates of my cycle and predic...       5   \n\n   thumbs_up          review_date  \\\n0          0  2018-01-21 04:23:11   \n1          0  2017-04-09 07:52:54   \n2          0  2024-06-19 05:49:45   \n3          0  2020-04-09 08:11:37   \n4          0  2020-08-05 20:56:00   \n\n                                  developer_response developer_response_date  \\\n0                                                NaN                     NaN   \n1                                                NaN                     NaN   \n2  Hello!\\n\\nThank you for your nice comment!\\nIf...     2024-06-21 16:35:19   \n3                                                NaN                     NaN   \n4                                                NaN                     NaN   \n\n  appVersion language_code country_code  \\\n0      5.8.0            en           us   \n1        NaN            en           us   \n2     10.2.1            en           us   \n3      7.2.2            en           us   \n4      7.5.0            en           us   \n\n                                            app_name  sentiment  \n0                            com.lbrc.PeriodCalendar          2  \n1  com.mobisystems.msdict.embedded.wireless.oxfor...          2  \n2                            com.lbrc.PeriodCalendar          2  \n3                            com.lbrc.PeriodCalendar          2  \n4                            com.lbrc.PeriodCalendar          2  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"##Oversampling","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\n# Initialize RandomOverSampler\nros = RandomOverSampler(random_state=42)\n\n# Since train_texts is a pandas Series, reshape it to a DataFrame\ntrain_texts_df = pd.DataFrame(train_texts)\n\n# Apply oversampling to balance the classes\ntrain_texts_resampled, train_labels_resampled = ros.fit_resample(train_texts_df, train_labels)\n\n# Convert the DataFrame of resampled texts back to a list\ntrain_texts_resampled = train_texts_resampled.squeeze().tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:40:59.938417Z","iopub.execute_input":"2024-11-19T17:40:59.938919Z","iopub.status.idle":"2024-11-19T17:40:59.948750Z","shell.execute_reply.started":"2024-11-19T17:40:59.938885Z","shell.execute_reply":"2024-11-19T17:40:59.947781Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from transformers import RobertaTokenizer\n\n# Load the RoBERTa tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Tokenize the text data\ntrain_encodings = tokenizer(train_texts_resampled, truncation=True, padding=True, max_length=128)\nval_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=128)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:41:02.358777Z","iopub.execute_input":"2024-11-19T17:41:02.359135Z","iopub.status.idle":"2024-11-19T17:41:06.216904Z","shell.execute_reply.started":"2024-11-19T17:41:02.359103Z","shell.execute_reply":"2024-11-19T17:41:06.216078Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7010f21b04c44777928a567a2f641617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbdefd7ab8fd461c88195417439f1f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de0c9e2f36584e3daf5a8a1e2491ac61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ddad90f2f534e64b19e87dc2673f1d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78265cfde39d46fe92bf76d90dd46fea"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass ReviewDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create PyTorch datasets\ntrain_dataset = ReviewDataset(train_encodings, train_labels_resampled)\nval_dataset = ReviewDataset(val_encodings, val_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:41:15.629518Z","iopub.execute_input":"2024-11-19T17:41:15.629868Z","iopub.status.idle":"2024-11-19T17:41:15.635936Z","shell.execute_reply.started":"2024-11-19T17:41:15.629835Z","shell.execute_reply":"2024-11-19T17:41:15.635100Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import RobertaConfig, RobertaForSequenceClassification\n\n# Load the configuration for RoBERTa with dropout\nconfig = RobertaConfig.from_pretrained('roberta-base', num_labels=3, hidden_dropout_prob=0.3, attention_probs_dropout_prob=0.3)\n\n# Load the pre-trained RoBERTa model for sequence classification\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base', config=config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:41:22.818102Z","iopub.execute_input":"2024-11-19T17:41:22.818450Z","iopub.status.idle":"2024-11-19T17:41:25.820701Z","shell.execute_reply.started":"2024-11-19T17:41:22.818418Z","shell.execute_reply":"2024-11-19T17:41:25.819815Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b8ebe42aad042ee8d9d9923db4dc817"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!pip install torch-optimizer --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:41:29.505142Z","iopub.execute_input":"2024-11-19T17:41:29.505964Z","iopub.status.idle":"2024-11-19T17:41:39.109719Z","shell.execute_reply.started":"2024-11-19T17:41:29.505926Z","shell.execute_reply":"2024-11-19T17:41:39.108666Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n# Optimizer: AdamW with weight decay\nlearning_rate = 3e-5\noptimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n\n# Scheduler for 2 epochs\nepochs = 2\ntotal_steps = len(train_loader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:41:39.111922Z","iopub.execute_input":"2024-11-19T17:41:39.112778Z","iopub.status.idle":"2024-11-19T17:41:39.594761Z","shell.execute_reply.started":"2024-11-19T17:41:39.112742Z","shell.execute_reply":"2024-11-19T17:41:39.594076Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Calculate class weights\nclasses = np.array([0, 1, 2])\nclass_weights = compute_class_weight('balanced', classes=classes, y=train_labels_resampled)\n\n# Convert weights to a PyTorch tensor\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Define the loss function with class weights\nloss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:41:44.202935Z","iopub.execute_input":"2024-11-19T17:41:44.204061Z","iopub.status.idle":"2024-11-19T17:41:44.350420Z","shell.execute_reply.started":"2024-11-19T17:41:44.204008Z","shell.execute_reply":"2024-11-19T17:41:44.349617Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Define the device\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# Convert the class labels to a NumPy array\nclasses = np.array([0, 1, 2])\n\n# Calculate class weights\nclass_weights = compute_class_weight('balanced', classes=classes, y=train_labels_resampled)\n\n# Convert to a PyTorch tensor and move it to the appropriate device\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n\n# Ensure `train_labels_resampled` is moved to the correct device\ntrain_labels_resampled = torch.tensor(train_labels_resampled, dtype=torch.long).to(device)\n\n# Use the weights in the loss function\nloss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:47:27.241796Z","iopub.execute_input":"2024-11-19T17:47:27.242219Z","iopub.status.idle":"2024-11-19T17:47:27.250798Z","shell.execute_reply.started":"2024-11-19T17:47:27.242185Z","shell.execute_reply":"2024-11-19T17:47:27.249875Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Move the model to the appropriate device\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)\n\n# Verify batch structure and device placement\nfor batch in train_loader:\n    # Print the structure of a batch\n    print(\"Batch Keys:\", batch.keys())\n    print(\"Input IDs shape:\", batch['input_ids'].shape)\n    print(\"Labels shape:\", batch['labels'].shape)\n    break  # Check only the first batch for debugging purposes\n\n# No unpacking errors here since we use dictionary keys\nprint(\"Model and data are ready for training on:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T17:50:53.544536Z","iopub.execute_input":"2024-11-19T17:50:53.544921Z","iopub.status.idle":"2024-11-19T17:50:53.726507Z","shell.execute_reply.started":"2024-11-19T17:50:53.544890Z","shell.execute_reply":"2024-11-19T17:50:53.725625Z"}},"outputs":[{"name":"stdout","text":"Batch Keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\nInput IDs shape: torch.Size([16, 128])\nLabels shape: torch.Size([16])\nModel and data are ready for training on: cuda\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}