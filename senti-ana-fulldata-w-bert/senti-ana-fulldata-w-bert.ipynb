{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dewanrapa/senti-ana-fulldata-w-bert?scriptVersionId=202890002\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-23T16:44:36.811822Z","iopub.execute_input":"2024-10-23T16:44:36.812121Z","iopub.status.idle":"2024-10-23T16:44:37.762406Z","shell.execute_reply.started":"2024-10-23T16:44:36.812088Z","shell.execute_reply":"2024-10-23T16:44:37.761184Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:44:37.764497Z","iopub.execute_input":"2024-10-23T16:44:37.764996Z","iopub.status.idle":"2024-10-23T16:44:38.812611Z","shell.execute_reply.started":"2024-10-23T16:44:37.764949Z","shell.execute_reply":"2024-10-23T16:44:38.81147Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Wed Oct 23 16:44:38 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   40C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nimport pandas as pd\nimport numpy as np\nimport time\nfrom joblib import Parallel, delayed\nimport multiprocessing","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:44:51.017118Z","iopub.execute_input":"2024-10-23T16:44:51.017982Z","iopub.status.idle":"2024-10-23T16:44:56.068674Z","shell.execute_reply.started":"2024-10-23T16:44:51.017934Z","shell.execute_reply":"2024-10-23T16:44:56.067706Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\nmodel = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n\n# Set the model to use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Check if using GPU\nif torch.cuda.is_available():\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"Using CPU\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:45:03.6193Z","iopub.execute_input":"2024-10-23T16:45:03.620371Z","iopub.status.idle":"2024-10-23T16:45:09.344226Z","shell.execute_reply.started":"2024-10-23T16:45:03.62033Z","shell.execute_reply":"2024-10-23T16:45:09.343213Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f5751bf838b43959d42b0dc7640ead2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1f6cd1548aa41568a7ff6e327a06198"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ebc0177d5324535842a2d43b212c07c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94d674e7c9094ce5bcc0df7cb1e16bd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f4c71c92724ff0a4fac9237448c771"}},"metadata":{}},{"name":"stdout","text":"Using GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"\nurl = 'https://raw.githubusercontent.com/amanullahshah32/Review-Scraping/refs/heads/main/Dataset/all_app_reviews.csv'\ndf = pd.read_csv(url)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:45:12.883273Z","iopub.execute_input":"2024-10-23T16:45:12.884085Z","iopub.status.idle":"2024-10-23T16:45:14.355063Z","shell.execute_reply.started":"2024-10-23T16:45:12.884019Z","shell.execute_reply":"2024-10-23T16:45:14.353982Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_shuffled = df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:45:24.247916Z","iopub.execute_input":"2024-10-23T16:45:24.248558Z","iopub.status.idle":"2024-10-23T16:45:24.319074Z","shell.execute_reply.started":"2024-10-23T16:45:24.248513Z","shell.execute_reply":"2024-10-23T16:45:24.318225Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_review_description = df_shuffled[['review_description']]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:46:08.559371Z","iopub.execute_input":"2024-10-23T16:46:08.559782Z","iopub.status.idle":"2024-10-23T16:46:08.573854Z","shell.execute_reply.started":"2024-10-23T16:46:08.559745Z","shell.execute_reply":"2024-10-23T16:46:08.572815Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"full_df = df[['review_description']]","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:46:38.848243Z","iopub.execute_input":"2024-10-23T16:46:38.848918Z","iopub.status.idle":"2024-10-23T16:46:38.855529Z","shell.execute_reply.started":"2024-10-23T16:46:38.848876Z","shell.execute_reply":"2024-10-23T16:46:38.854563Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"full_df","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:46:45.154048Z","iopub.execute_input":"2024-10-23T16:46:45.154802Z","iopub.status.idle":"2024-10-23T16:46:45.170223Z","shell.execute_reply.started":"2024-10-23T16:46:45.154761Z","shell.execute_reply":"2024-10-23T16:46:45.169352Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                review_description\n0                                             nice\n1                                             good\n2                                             good\n3                                             good\n4                                           good üòä\n...                                            ...\n99390                                          wow\n99391       ‡¶∞‡ßç‡¶ó‡¶¨‡¶¨‡¶§‡ßÄ ‡¶ó‡¶∞‡ßÅ ‡¶ñ‡¶ø‡¶ö‡¶®‡¶ø ‡¶∞‡ßã‡¶ó ‡¶ö‡¶ø‡¶ï‡¶ø‡¶õ‡ßç‡¶Ø‡¶æ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂\n99392                                         good\n99393  ‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™, ‡¶ì‡¶∑‡ßÅ‡¶ß‡ßá‡¶∞ ‡¶°‡ßã‡¶ú ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶§‡¶æ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶®‡¶æ‡¶á\n99394                                     nice app\n\n[99395 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nice</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good üòä</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99390</th>\n      <td>wow</td>\n    </tr>\n    <tr>\n      <th>99391</th>\n      <td>‡¶∞‡ßç‡¶ó‡¶¨‡¶¨‡¶§‡ßÄ ‡¶ó‡¶∞‡ßÅ ‡¶ñ‡¶ø‡¶ö‡¶®‡¶ø ‡¶∞‡ßã‡¶ó ‡¶ö‡¶ø‡¶ï‡¶ø‡¶õ‡ßç‡¶Ø‡¶æ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂</td>\n    </tr>\n    <tr>\n      <th>99392</th>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>99393</th>\n      <td>‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™, ‡¶ì‡¶∑‡ßÅ‡¶ß‡ßá‡¶∞ ‡¶°‡ßã‡¶ú ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶§‡¶æ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶®‡¶æ‡¶á</td>\n    </tr>\n    <tr>\n      <th>99394</th>\n      <td>nice app</td>\n    </tr>\n  </tbody>\n</table>\n<p>99395 rows √ó 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_review_description.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:47:09.002467Z","iopub.execute_input":"2024-10-23T16:47:09.002853Z","iopub.status.idle":"2024-10-23T16:47:09.011841Z","shell.execute_reply.started":"2024-10-23T16:47:09.002816Z","shell.execute_reply":"2024-10-23T16:47:09.010831Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                      review_description\n0             Excellent app for learning\n1  Is helping me to quit this ugly habit\n2                               Excelent\n3                                  Noice\n4                                  Ripon","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Excellent app for learning</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Is helping me to quit this ugly habit</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Excelent</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Noice</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ripon</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ndef sentiment_score(review):\n    # Handle missing or non-string values by converting to empty strings\n    if not isinstance(review, str):\n        review = ''\n    \n    # Tokenize and move the tokens to GPU\n    tokens = tokenizer.encode(review, return_tensors='pt').to(device)\n    \n    # Perform inference on GPU\n    result = model(tokens)\n    \n    # Return the sentiment score (1-5 scale)\n    return int(torch.argmax(result.logits)) + 1","metadata":{"execution":{"iopub.status.busy":"2024-10-23T16:47:46.672933Z","iopub.execute_input":"2024-10-23T16:47:46.673803Z","iopub.status.idle":"2024-10-23T16:47:46.678992Z","shell.execute_reply.started":"2024-10-23T16:47:46.673759Z","shell.execute_reply":"2024-10-23T16:47:46.678094Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Step 1: Clean the DataFrame by replacing non-string values\nfull_df['review_description'] = full_df['review_description'].apply(lambda x: x if isinstance(x, str) else '')\n\n# Step 2: Measure the start time\nstart_time = time.time()\n\n# Step 3: Apply sentiment scoring\nfull_df['sentiment_full_df'] = df_review_description['review_description'].apply(lambda review: sentiment_score(review[:512]))\n\n# Step 4: Measure the end time and print the total time taken\nend_time = time.time()\nprint(f\"Time taken: {end_time - start_time} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:04:08.4789Z","iopub.execute_input":"2024-10-23T17:04:08.479197Z","iopub.status.idle":"2024-10-23T17:19:42.442479Z","shell.execute_reply.started":"2024-10-23T17:04:08.479166Z","shell.execute_reply":"2024-10-23T17:19:42.441458Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3721606111.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  full_df['review_description'] = full_df['review_description'].apply(lambda x: x if isinstance(x, str) else '')\n","output_type":"stream"},{"name":"stdout","text":"Time taken: 933.9244675636292 seconds\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/3721606111.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  full_df['sentiment_full_df'] = df_review_description['review_description'].apply(lambda review: sentiment_score(review[:512]))\n","output_type":"stream"}]},{"cell_type":"code","source":"full_df.sentiment_full_df.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:19:42.443683Z","iopub.execute_input":"2024-10-23T17:19:42.443994Z","iopub.status.idle":"2024-10-23T17:19:42.454237Z","shell.execute_reply.started":"2024-10-23T17:19:42.44396Z","shell.execute_reply":"2024-10-23T17:19:42.453256Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"sentiment_full_df\n5    57141\n4    25077\n1     8174\n3     6533\n2     2470\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"full_df.sentiment_full_df.isnull()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:19:42.455327Z","iopub.execute_input":"2024-10-23T17:19:42.455656Z","iopub.status.idle":"2024-10-23T17:19:42.468712Z","shell.execute_reply.started":"2024-10-23T17:19:42.455624Z","shell.execute_reply":"2024-10-23T17:19:42.467732Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0        False\n1        False\n2        False\n3        False\n4        False\n         ...  \n99390    False\n99391    False\n99392    False\n99393    False\n99394    False\nName: sentiment_full_df, Length: 99395, dtype: bool"},"metadata":{}}]},{"cell_type":"code","source":"# Step 5: Remove rows where sentiment_full_df is null\nfull_df_cleaned = full_df.dropna(subset=['sentiment_full_df'])\n\n# Verify that no null values are present\nprint(f\"Number of nulls in 'sentiment_full_df': {full_df_cleaned['sentiment_full_df'].isnull().sum()}\")\n\n# Optional: Show the shape of the cleaned DataFrame to see how many rows are left\nprint(f\"Cleaned DataFrame shape: {full_df_cleaned.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:19:42.469875Z","iopub.execute_input":"2024-10-23T17:19:42.470163Z","iopub.status.idle":"2024-10-23T17:19:42.481636Z","shell.execute_reply.started":"2024-10-23T17:19:42.470132Z","shell.execute_reply":"2024-10-23T17:19:42.480754Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Number of nulls in 'sentiment_full_df': 0\nCleaned DataFrame shape: (99395, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"full_df_cleaned","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:19:42.482603Z","iopub.execute_input":"2024-10-23T17:19:42.482876Z","iopub.status.idle":"2024-10-23T17:19:42.497308Z","shell.execute_reply.started":"2024-10-23T17:19:42.482846Z","shell.execute_reply":"2024-10-23T17:19:42.496143Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                review_description  sentiment_full_df\n0                                             nice                  5\n1                                             good                  5\n2                                             good                  5\n3                                             good                  2\n4                                           good üòä                  1\n...                                            ...                ...\n99390                                          wow                  1\n99391       ‡¶∞‡ßç‡¶ó‡¶¨‡¶¨‡¶§‡ßÄ ‡¶ó‡¶∞‡ßÅ ‡¶ñ‡¶ø‡¶ö‡¶®‡¶ø ‡¶∞‡ßã‡¶ó ‡¶ö‡¶ø‡¶ï‡¶ø‡¶õ‡ßç‡¶Ø‡¶æ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂                  3\n99392                                         good                  5\n99393  ‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™, ‡¶ì‡¶∑‡ßÅ‡¶ß‡ßá‡¶∞ ‡¶°‡ßã‡¶ú ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶§‡¶æ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶®‡¶æ‡¶á                  5\n99394                                     nice app                  5\n\n[99395 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_description</th>\n      <th>sentiment_full_df</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nice</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>good</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>good</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>good</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good üòä</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99390</th>\n      <td>wow</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99391</th>\n      <td>‡¶∞‡ßç‡¶ó‡¶¨‡¶¨‡¶§‡ßÄ ‡¶ó‡¶∞‡ßÅ ‡¶ñ‡¶ø‡¶ö‡¶®‡¶ø ‡¶∞‡ßã‡¶ó ‡¶ö‡¶ø‡¶ï‡¶ø‡¶õ‡ßç‡¶Ø‡¶æ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>99392</th>\n      <td>good</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>99393</th>\n      <td>‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™, ‡¶ì‡¶∑‡ßÅ‡¶ß‡ßá‡¶∞ ‡¶°‡ßã‡¶ú ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶§‡¶æ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶®‡¶æ‡¶á</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>99394</th>\n      <td>nice app</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>99395 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":" full_df_cleaned['sentiment_full_df'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T17:31:32.160416Z","iopub.execute_input":"2024-10-23T17:31:32.161147Z","iopub.status.idle":"2024-10-23T17:31:32.169778Z","shell.execute_reply.started":"2024-10-23T17:31:32.161083Z","shell.execute_reply":"2024-10-23T17:31:32.168785Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"sentiment_full_df\n5    57141\n4    25077\n1     8174\n3     6533\n2     2470\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}